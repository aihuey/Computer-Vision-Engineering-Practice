{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8ddef3-a96f-4a5d-910d-836ee28f1971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f68ac5-f055-420e-bf3b-5bfccda6c3d1",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;\">\n",
    "    <figure>\n",
    "        <img src=\"assets/img1.jpg\" width=\"400\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片1</figcaption>\n",
    "    </figure>\n",
    "    <figure>\n",
    "        <img src=\"assets/img2.jpg\" width=\"400\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片2</figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "<div style=\"display: flex;\">\n",
    "    <figure>\n",
    "        <img src=\"assets/img3.jpg\" width=\"400\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片3</figcaption>\n",
    "    </figure>\n",
    "    <figure>\n",
    "        <img src=\"assets/img4.jpg\" width=\"400\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片4</figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "<div style=\"display: flex;\">\n",
    "    <figure>\n",
    "        <img src=\"assets/img5.jpg\" width=\"400\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片5</figcaption>\n",
    "    </figure>\n",
    "    <figure>\n",
    "        <img src=\"assets/img6.jpg\" width=\"400\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片6</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d73f96-1eb2-4d06-9744-bd0120140f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stitcher:\n",
    "\n",
    "    # 拼接函数\n",
    "    def stitch(self, images, ratio = 0.75, reprojThresh = 4.0, showMatches = True):\n",
    "        # 读取图像\n",
    "        imageA, imageB = images\n",
    "        # 计算特征点和特征向量\n",
    "        kpsA, featureA = self.detectAndDescribe(imageA)\n",
    "        kpsB, featureB = self.detectAndDescribe(imageB)\n",
    "\n",
    "        # 匹配两张图片的特征点\n",
    "        M = self.matchKeypoints(kpsA, kpsB, featureA, featureB, ratio, reprojThresh)\n",
    "\n",
    "        # 没有匹配点，退出\n",
    "        if not M:\n",
    "            return None\n",
    "\n",
    "        matches, H, status = M\n",
    "        # 将图片B进行视角变换 中间结果\n",
    "        result = cv2.warpPerspective\\\n",
    "            (imageB, H, (imageA.shape[1] + imageB.shape[1], imageA.shape[0]))\n",
    "        cv2.imshow('h',result)\n",
    "        # 将图片A传入\n",
    "        result[0:imageA.shape[0], 0:imageA.shape[1]] = imageA\n",
    "\n",
    "        # 计算混合渐变\n",
    "        mask = np.zeros((imageA.shape[0], imageA.shape[1]), dtype=np.uint8)\n",
    "        mask[:, imageA.shape[1]-40:] = 255\n",
    "        result = cv2.seamlessClone(imageA, result, mask, (imageA.shape[1], imageA.shape[0]//2), cv2.NORMAL_CLONE)\n",
    "        \n",
    "        result = self.trim_border(result)\n",
    "\n",
    "        # 检测是否需要显示图片匹配\n",
    "        if showMatches:\n",
    "            # 生成匹配图片\n",
    "            vis = self.drawMatches(imageA, imageB, kpsA, kpsB, matches, status)\n",
    "            # 返回结果A\n",
    "            return result, vis\n",
    "\n",
    "        # 返回匹配结果\n",
    "        return result\n",
    "\n",
    "\n",
    "    def detectAndDescribe(self, image):\n",
    "        # 转换为灰度图\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 建立SIFT生成器\n",
    "        descriptor = cv2.SIFT_create()\n",
    "        # 检测特征点并计算描述子\n",
    "        kps, features = descriptor.detectAndCompute(gray, None)\n",
    "\n",
    "        kps = np.float32([kp.pt for kp in kps])\n",
    "\n",
    "        return kps, features\n",
    "\n",
    "    def matchKeypoints(self, kpsA, kpsB, featureA, featureB, ratio, reprojThresh):\n",
    "        # 建立暴力匹配器\n",
    "        matcher = cv2.BFMatcher()\n",
    "\n",
    "        # 使用KNN检测来自AB图的SIFT特征匹配\n",
    "        rawMatches = matcher.knnMatch(featureA, featureB, 2)\n",
    "\n",
    "        # 过滤\n",
    "        matches = []\n",
    "        for m in rawMatches:\n",
    "            if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "                matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "\n",
    "        if len(matches) > 4:\n",
    "            # 获取匹配对的点坐标\n",
    "            ptsA = np.float32([kpsA[i] for (_, i) in matches])\n",
    "            ptsB = np.float32([kpsB[i] for (i, _) in matches])\n",
    "\n",
    "            # 计算H矩阵\n",
    "            H, status = cv2.findHomography(ptsB, ptsA, cv2.RANSAC, reprojThresh)\n",
    "\n",
    "            return matches, H, status\n",
    "\n",
    "    # 展示图像\n",
    "    def cv_show(self,name, img):\n",
    "        cv2.imshow(name, img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def drawMatches(self, imageA, imageB, kpsA, kpsB, matches, status):\n",
    "        # 初始化可视化图片，将A、B图左右连接到一起\n",
    "        hA, wA = imageA.shape[:2]\n",
    "        hB, wB = imageB.shape[:2]\n",
    "        vis = np.zeros((max(hA, hB), wA + wB, 3), dtype=\"uint8\")\n",
    "        vis[0:hA, 0:wA] = imageA\n",
    "        vis[0:hB, wA:(wA+wB)] = imageB\n",
    "\n",
    "        # 联合遍历，画出匹配对\n",
    "        for ((trainIdx, queryIdx), s) in zip(matches, status):\n",
    "            # 当点对匹配成功时，画到可视化图上\n",
    "            if s == 1:\n",
    "                # 画出匹配对\n",
    "                ptA = (int(kpsA[queryIdx][0]), int(kpsA[queryIdx][1]))\n",
    "                ptB = (int(kpsB[trainIdx][0]) + wA, int(kpsB[trainIdx][1]))\n",
    "                cv2.line(vis, ptA, ptB, (0, 255, 0), 1)\n",
    "\n",
    "        # 返回可视化结果\n",
    "        return vis\n",
    "    \n",
    "    def trim_border(self, img):\n",
    "        # 转换为灰度图像\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 二值化\n",
    "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "        # 寻找轮廓\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # 找到最大的轮廓\n",
    "        max_area = 0\n",
    "        max_contour = None\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                max_contour = contour\n",
    "\n",
    "        # 计算最大轮廓的边界矩形\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "        # 使用透视变换裁剪图像\n",
    "        src_points = np.float32([[x, y], [x + w, y], [x, y + h], [x + w, y + h]])\n",
    "        dst_points = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "        M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "        cropped_img = cv2.warpPerspective(img, M, (w, h))\n",
    "\n",
    "        return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8339bb78-671c-4cbc-b085-3bf28591615a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取图片\n",
    "img1 = cv2.imread('./assets/img2.jpg')\n",
    "img2 = cv2.imread('./assets/img1.jpg')\n",
    "\n",
    "\n",
    "# 图片拼接\n",
    "stitcher = Stitcher()\n",
    "result, vis = stitcher.stitch([img1, img2], showMatches=True)\n",
    "# cv2.imshow('img1', img1)\n",
    "# cv2.imshow('img2', img2)\n",
    "cv2.namedWindow('keypoints matches',0)\n",
    "cv2.resizeWindow('keypoints matches',(img1.shape[1]+img2.shape[1],img1.shape[0]))\n",
    "cv2.imshow('keypoints matches',vis)\n",
    "cv2.namedWindow('result',0)\n",
    "cv2.resizeWindow('result',(img1.shape[1]+img2.shape[1],img1.shape[0]))\n",
    "cv2.imshow('result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"./assets/result.jpg\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e224454-ecd9-4209-b144-72b3ac286e8b",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;\">\n",
    "    <figure>\n",
    "        <img src=\"assets/result1.jpg\" width=\"800\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片1和2拼接结果</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "def907e4-f1d5-404a-87fa-e11043f2461c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取图片\n",
    "img1 = cv2.imread('./assets/img3.jpg')\n",
    "img2 = cv2.imread('./assets/img4.jpg')\n",
    "\n",
    "\n",
    "# 图片拼接\n",
    "stitcher = Stitcher()\n",
    "result, vis = stitcher.stitch([img1, img2], showMatches=True)\n",
    "cv2.namedWindow('keypoints matches',0)\n",
    "cv2.resizeWindow('keypoints matches',(img1.shape[1]+img2.shape[1],img1.shape[0]))\n",
    "cv2.imshow('keypoints matches',vis)\n",
    "cv2.namedWindow('result',0)\n",
    "cv2.resizeWindow('result',(img1.shape[1]+img2.shape[1],img1.shape[0]))\n",
    "cv2.imshow('result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"./assets/result2.jpg\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30bde4-d315-45a7-9236-4d408efab9da",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;\">\n",
    "    <figure>\n",
    "        <img src=\"assets/result2.jpg\" width=\"800\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片3和4拼接结果</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efed494a-33d7-4a31-9a4f-e1b118c5ccf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取图片\n",
    "img1 = cv2.imread('./assets/img6.jpg')\n",
    "img2 = cv2.imread('./assets/img6.jpg')\n",
    "\n",
    "# 图片拼接\n",
    "stitcher = Stitcher()\n",
    "result, vis = stitcher.stitch([img1, img2], showMatches=True)\n",
    "cv2.namedWindow('keypoints matches',0)\n",
    "cv2.resizeWindow('keypoints matches',(img1.shape[1]+img2.shape[1],img1.shape[0]))\n",
    "cv2.imshow('keypoints matches',vis)\n",
    "cv2.namedWindow('result',0)\n",
    "cv2.resizeWindow('result',(img1.shape[1]+img2.shape[1],img1.shape[0]))\n",
    "cv2.imshow('result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"./assets/result3.jpg\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1515fc-11e9-409d-a1b4-14c7a54c2a48",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex;\">\n",
    "    <figure>\n",
    "        <img src=\"assets/result3.jpg\" width=\"800\"/>\n",
    "        <figcaption style=\"text-align: center;\">图片5和6拼接结果</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc18c2-4514-437a-b6e2-5723b37cf65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
